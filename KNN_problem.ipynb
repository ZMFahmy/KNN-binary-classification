{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Importing libraries"
      ],
      "metadata": {
        "id": "tgMG2xcuw4zH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "DZoQQBFAUwQ9"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing arrays of dependent and independent variables"
      ],
      "metadata": {
        "id": "qNUS_6fExVLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('magic04.data')\n",
        "X = dataset.iloc[:, :-1].values # Matrix of features\n",
        "y = dataset.iloc[:, -1].values # Vector of predicted values"
      ],
      "metadata": {
        "id": "CGkTItD5U9NQ"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqI-s8iDWCAh",
        "outputId": "8d678d45-cdb5-42b2-f4c9-5421212d43b1"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 31.6036  11.7235   2.5185 ...  -9.9574   6.3609 205.261 ]\n",
            " [162.052  136.031    4.0612 ... -45.216   76.96   256.788 ]\n",
            " [ 23.8172   9.5728   2.3385 ...  -7.1513  10.449  116.737 ]\n",
            " ...\n",
            " [ 75.4455  47.5305   3.4483 ...  -9.4662  30.2987 256.5166]\n",
            " [120.5135  76.9018   3.9939 ... -63.8389  84.6874 408.3166]\n",
            " [187.1814  53.0014   3.2093 ...  31.4755  52.731  272.3174]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXQ4MetAWDm7",
        "outputId": "b295d91d-e783-414a-fd9b-ecd361211ab9"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['g' 'g' 'g' ... 'h' 'h' 'h']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Balancing out the data"
      ],
      "metadata": {
        "id": "NZzEl8u6x3ae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We count the appearance of each class in our dataset\n",
        "\n",
        "g_counter = 0\n",
        "h_counter = 0\n",
        "\n",
        "for c in y:\n",
        "  if c == 'g':\n",
        "    g_counter += 1\n",
        "  else:\n",
        "    h_counter += 1"
      ],
      "metadata": {
        "id": "n50JPD6sWyl8"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(g_counter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58kcj5lJXIIW",
        "outputId": "4a3f9177-8580-4606-deaa-48182dd0f8f5"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12331\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(h_counter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-zK-r1TXVbV",
        "outputId": "7d7ae0e0-0506-45a5-af25-02bcbea9dbaf"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We balance the dataset by randomly removing extra data points\n",
        "# that result in the g class until both classes are approximately equal\n",
        "\n",
        "i = 0\n",
        "indices = []\n",
        "\n",
        "while g_counter > h_counter:\n",
        "  if y[i] == 'g':\n",
        "    indices.append(i)\n",
        "    g_counter -= 1\n",
        "  i += 1\n",
        "\n",
        "# We remove the same rows from both X and y\n",
        "\n",
        "X = np.delete(X, indices, axis=0)\n",
        "y = np.delete(y, indices, axis=0)"
      ],
      "metadata": {
        "id": "8ffO-9cYXZtY"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting the data to training, validation, and test sets"
      ],
      "metadata": {
        "id": "YFniHiOryDEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# training set will be 70% of dataset\n",
        "X_train, X_rest, y_train, y_rest = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "# the remaining 30% is divided equally among validation and test sets\n",
        "X_validation, X_test, y_validation, y_test = train_test_split(X_rest, y_rest, test_size=0.5)"
      ],
      "metadata": {
        "id": "55v7Ke8QgexK"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performing feature scaling"
      ],
      "metadata": {
        "id": "Rrdh-6JUyOHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Performing feature scaling is necessary, so that no features dominate\n",
        "# the model due to their large range\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_validation = sc.transform(X_validation)\n",
        "X_test = sc.transform(X_test)"
      ],
      "metadata": {
        "id": "uqPcwE11vrld"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAnNNYhqwLG9",
        "outputId": "ffefdd92-983b-4c3f-fcb3-6fd60525fe2f"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.55938563 -0.01786021  0.29032034 ...  0.52812729  0.44791916\n",
            "  -1.08881334]\n",
            " [-0.45646009 -0.72100486 -1.131196   ...  0.03609442 -1.04990346\n",
            "  -1.58512567]\n",
            " [ 0.97688509  1.55259087  0.89538996 ...  2.25657366 -0.9544033\n",
            "   1.35794931]\n",
            " ...\n",
            " [ 0.48523742  0.0872283   1.32755267 ...  0.68950018 -1.05033688\n",
            "   0.8139234 ]\n",
            " [-0.15282417 -0.65202693 -0.57045077 ...  0.36690332 -1.08818872\n",
            "  -0.14491771]\n",
            " [-0.67376763 -0.34836803 -0.08706412 ... -0.46364414 -1.02963283\n",
            "  -0.18647343]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training model on training set"
      ],
      "metadata": {
        "id": "D2gBo2NayUxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Standard is using minkowski metric, which uses manhattan distance if\n",
        "# p=1, and uses euclidean distance if p=2\n",
        "classifier = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\n",
        "\n",
        "# Training model on training set\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "zQppYm3Awv6F",
        "outputId": "cbec9508-6717-4254-b841-b7ddccae596f"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Choosing the best k value to use"
      ],
      "metadata": {
        "id": "MEMIrVLiyZGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "suggested_neighbors = range(1, 21)\n",
        "\n",
        "# We will store these metrics for analysing performance the of model with\n",
        "# different K values later\n",
        "\n",
        "accuracy_scores_on_validation = []\n",
        "precision_scores_on_validation = []\n",
        "recall_scores_on_validation = []\n",
        "f_scores_on_validation = []\n",
        "confusion_matrices_on_validation = []\n",
        "\n",
        "accuracy_scores_on_test = []\n",
        "precision_scores_on_test = []\n",
        "recall_scores_on_test = []\n",
        "f_scores_on_test = []\n",
        "confusion_matrices_on_test = []\n",
        "\n",
        "# Getting scores by comparing predictions and true values from validation set\n",
        "for k in suggested_neighbors:\n",
        "  classifier.n_neighbors = k\n",
        "  y_pred = classifier.predict(X_validation)\n",
        "\n",
        "  accuracy_scores_on_validation.append(accuracy_score(y_validation, y_pred))\n",
        "\n",
        "  precision = precision_score(y_validation, y_pred, pos_label='g')\n",
        "  precision_scores_on_validation.append(precision)\n",
        "\n",
        "  recall = recall_score(y_validation, y_pred, pos_label='g')\n",
        "  recall_scores_on_validation.append(recall)\n",
        "\n",
        "  f_scores_on_validation.append(2 * (precision * recall) / (precision + recall))\n",
        "\n",
        "  confusion_matrices_on_validation.append(confusion_matrix(y_validation, y_pred))\n",
        "\n",
        "# Getting scores by comparing predictions and true values from test set\n",
        "for k in suggested_neighbors:\n",
        "  classifier.n_neighbors = k\n",
        "  y_pred = classifier.predict(X_test)\n",
        "\n",
        "  accuracy_scores_on_test.append(accuracy_score(y_test, y_pred))\n",
        "\n",
        "  precision = precision_score(y_test, y_pred, pos_label='g')\n",
        "  precision_scores_on_test.append(precision)\n",
        "\n",
        "  recall = recall_score(y_test, y_pred, pos_label='g')\n",
        "  recall_scores_on_test.append(recall)\n",
        "\n",
        "  f_scores_on_test.append(2 * (precision * recall) / (precision + recall))\n",
        "\n",
        "  confusion_matrices_on_test.append(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Selecting most efficient K\n",
        "best_k = pd.Series(accuracy_scores_on_validation).idxmax() + 1\n",
        "classifier.n_neighbors = best_k"
      ],
      "metadata": {
        "id": "uKW1oNOYyASn"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Hypothetically, model works best at n_neighbors = {best_k}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jH6Cqvx2-3ua",
        "outputId": "3e347f5b-3309-49f9-9c6a-92c55ac4a04f"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hypothetically, model works best at n_neighbors = 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing performance metrics for different models"
      ],
      "metadata": {
        "id": "SwnaiTz4ypwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable, ALL\n",
        "report_table_on_validation = PrettyTable([\"K value\", \"Accuracy\", \"Precision\", \"Recall\", \"F-score\", \"Confusion matrix\"])\n",
        "report_table_on_validation.hrules = ALL\n",
        "\n",
        "report_table_on_test = PrettyTable([\"K value\", \"Accuracy\", \"Precision\", \"Recall\", \"F-score\", \"Confusion matrix\"])\n",
        "report_table_on_test.hrules = ALL\n",
        "\n",
        "for i in range(0, 20):\n",
        "  accuracy = float(\"{:.4f}\".format(accuracy_scores_on_validation[i]))\n",
        "  precision = float(\"{:.4f}\".format(precision_scores_on_validation[i]))\n",
        "  recall = float(\"{:.4f}\".format(recall_scores_on_validation[i]))\n",
        "  f_score = float(\"{:.4f}\".format(f_scores_on_validation[i]))\n",
        "  cm = confusion_matrices_on_validation[i]\n",
        "\n",
        "  report_table_on_validation.add_row([i+1, accuracy, precision, recall, f_score, cm])\n",
        "\n",
        "for i in range(0, 20):\n",
        "  accuracy = float(\"{:.4f}\".format(accuracy_scores_on_test[i]))\n",
        "  precision = float(\"{:.4f}\".format(precision_scores_on_test[i]))\n",
        "  recall = float(\"{:.4f}\".format(recall_scores_on_test[i]))\n",
        "  f_score = float(\"{:.4f}\".format(f_scores_on_test[i]))\n",
        "  cm = confusion_matrices_on_test[i]\n",
        "\n",
        "  report_table_on_test.add_row([i+1, accuracy, precision, recall, f_score, cm])\n",
        "\n",
        "\n",
        "\n",
        "print(\"                       Results on Validation set\")\n",
        "print(report_table_on_validation)\n",
        "\n",
        "print(\"\\n\\n                       Results on Test set\")\n",
        "print(report_table_on_test)\n",
        "\n",
        "print(f\"\\nBest accuracy on test data = {max(accuracy_scores_on_test)}, using k = {pd.Series(accuracy_scores_on_validation).idxmax() + 1}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ViUGMT_024m",
        "outputId": "a409e18c-7a59-4c4c-e89f-d7d2c6221c10"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       Results on Validation set\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "| K value | Accuracy | Precision | Recall | F-score | Confusion matrix |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    1    |  0.7856  |   0.7496  | 0.8547 |  0.7987 |    [[853 145]    |\n",
            "|         |          |           |        |         |    [285 723]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    2    |  0.7537  |   0.6839  | 0.9389 |  0.7914 |    [[937  61]    |\n",
            "|         |          |           |        |         |    [433 575]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    3    |  0.7926  |   0.7496  | 0.8758 |  0.8078 |    [[874 124]    |\n",
            "|         |          |           |        |         |    [292 716]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    4    |  0.7827  |   0.7165  | 0.9319 |  0.8101 |    [[930  68]    |\n",
            "|         |          |           |        |         |    [368 640]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    5    |  0.8046  |   0.7577  | 0.8928 |  0.8197 |    [[891 107]    |\n",
            "|         |          |           |        |         |    [285 723]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    6    |  0.7916  |   0.7294  | 0.9238 |  0.8152 |    [[922  76]    |\n",
            "|         |          |           |        |         |    [342 666]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    7    |  0.8096  |   0.7606  | 0.9008 |  0.8248 |    [[899  99]    |\n",
            "|         |          |           |        |         |    [283 725]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    8    |  0.8046  |   0.7432  | 0.9279 |  0.8253 |    [[926  72]    |\n",
            "|         |          |           |        |         |    [320 688]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    9    |  0.8146  |   0.7666  | 0.9018 |  0.8287 |    [[900  98]    |\n",
            "|         |          |           |        |         |    [274 734]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    10   |  0.8051  |   0.7454  | 0.9238 |  0.8251 |    [[922  76]    |\n",
            "|         |          |           |        |         |    [315 693]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    11   |  0.8156  |   0.7666  | 0.9048 |   0.83  |    [[903  95]    |\n",
            "|         |          |           |        |         |    [275 733]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    12   |  0.8106  |   0.7516  | 0.9248 |  0.8293 |    [[923  75]    |\n",
            "|         |          |           |        |         |    [305 703]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    13   |  0.8166  |   0.7669  | 0.9068 |  0.831  |    [[905  93]    |\n",
            "|         |          |           |        |         |    [275 733]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    14   |  0.8131  |   0.7526  | 0.9299 |  0.8319 |    [[928  70]    |\n",
            "|         |          |           |        |         |    [305 703]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    15   |  0.817   |   0.7681  | 0.9058 |  0.8313 |    [[904  94]    |\n",
            "|         |          |           |        |         |    [273 735]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    16   |  0.8111  |   0.7543  | 0.9198 |  0.8289 |    [[918  80]    |\n",
            "|         |          |           |        |         |    [299 709]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    17   |  0.8151  |   0.765   | 0.9068 |  0.8299 |    [[905  93]    |\n",
            "|         |          |           |        |         |    [278 730]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    18   |  0.8096  |   0.752   | 0.9208 |  0.8279 |    [[919  79]    |\n",
            "|         |          |           |        |         |    [303 705]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    19   |  0.8136  |   0.7622  | 0.9088 |  0.8291 |    [[907  91]    |\n",
            "|         |          |           |        |         |    [283 725]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    20   |  0.8106  |   0.7529  | 0.9218 |  0.8288 |    [[920  78]    |\n",
            "|         |          |           |        |         |    [302 706]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "\n",
            "\n",
            "                       Results on Test set\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "| K value | Accuracy | Precision | Recall | F-score | Confusion matrix |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    1    |  0.7833  |   0.755   | 0.8345 |  0.7928 |    [[832 165]    |\n",
            "|         |          |           |        |         |    [270 740]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    2    |  0.7768  |   0.7087  | 0.9348 |  0.8062 |    [[932  65]    |\n",
            "|         |          |           |        |         |    [383 627]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    3    |  0.7992  |   0.7633  | 0.8636 |  0.8104 |    [[861 136]    |\n",
            "|         |          |           |        |         |    [267 743]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    4    |  0.7917  |   0.7278  | 0.9278 |  0.8157 |    [[925  72]    |\n",
            "|         |          |           |        |         |    [346 664]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    5    |  0.8022  |   0.7595  | 0.8806 |  0.8156 |    [[878 119]    |\n",
            "|         |          |           |        |         |    [278 732]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    6    |  0.8012  |   0.7431  | 0.9168 |  0.8208 |    [[914  83]    |\n",
            "|         |          |           |        |         |    [316 694]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    7    |  0.8082  |   0.7642  | 0.8877 |  0.8213 |    [[885 112]    |\n",
            "|         |          |           |        |         |    [273 737]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    8    |  0.8062  |    0.75   | 0.9147 |  0.8242 |    [[912  85]    |\n",
            "|         |          |           |        |         |    [304 706]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    9    |  0.8067  |   0.7673  | 0.8766 |  0.8184 |    [[874 123]    |\n",
            "|         |          |           |        |         |    [265 745]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    10   |  0.8102  |   0.7558  | 0.9127 |  0.8269 |    [[910  87]    |\n",
            "|         |          |           |        |         |    [294 716]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    11   |  0.8127  |   0.7702  | 0.8877 |  0.8248 |    [[885 112]    |\n",
            "|         |          |           |        |         |    [264 746]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    12   |  0.8122  |   0.7579  | 0.9137 |  0.8286 |    [[911  86]    |\n",
            "|         |          |           |        |         |    [291 719]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    13   |  0.8137  |   0.7688  | 0.8937 |  0.8265 |    [[891 106]    |\n",
            "|         |          |           |        |         |    [268 742]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    14   |  0.8092  |   0.7537  | 0.9147 |  0.8265 |    [[912  85]    |\n",
            "|         |          |           |        |         |    [298 712]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    15   |  0.8097  |   0.7621  | 0.8967 |  0.824  |    [[894 103]    |\n",
            "|         |          |           |        |         |    [279 731]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    16   |  0.8057  |   0.7531  | 0.9057 |  0.8224 |    [[903  94]    |\n",
            "|         |          |           |        |         |    [296 714]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    17   |  0.8082  |   0.7624  | 0.8917 |  0.822  |    [[889 108]    |\n",
            "|         |          |           |        |         |    [277 733]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    18   |  0.8062  |   0.7529  | 0.9077 |  0.8231 |    [[905  92]    |\n",
            "|         |          |           |        |         |    [297 713]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    19   |  0.8062  |   0.7616  | 0.8877 |  0.8198 |    [[885 112]    |\n",
            "|         |          |           |        |         |    [277 733]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "|    20   |  0.8072  |   0.7546  | 0.9067 |  0.8237 |    [[904  93]    |\n",
            "|         |          |           |        |         |    [294 716]]    |\n",
            "+---------+----------+-----------+--------+---------+------------------+\n",
            "\n",
            "Best accuracy on test data = 0.8136522172396612, using k = 15\n"
          ]
        }
      ]
    }
  ]
}